{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Retrieval 과제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실습시간에는 VGG19와 ResNet을 Feature Extractor로 사용했는데, 이번 과제에서는 DenseNet을 Feature Extractor로 사용해봅니다.\n",
    "\n",
    "추가로 data는 저번에 Image Retrieval을 위해 사용했던 data를 그대로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet, self).__init__()\n",
    "        self.densenet = torchvision.models.densenet121(pretrained = True) # DensetNet model is imported\n",
    "        \n",
    "        # add the codes\n",
    "                \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.densenet(x)\n",
    "        \n",
    "        # Hint : https://pytorch.org/docs/stable/_modules/torchvision/models/densenet.html#densenet121\n",
    "        out = F.relu(out, inplace=True)\n",
    "        out = ???\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Set our model with pre-trained model \n",
    "densenet = DenseNet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract ConvNet Features (VGG19, ResNet)\n",
    "def extract_deep_features(path, feature_extractor, feature_size):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    list_imgs_names = os.listdir(path) #list_imgs_names\n",
    "    N = len(list_imgs_names)\n",
    "    feature_all = np.zeros((N, feature_size)) # create an array to store features\n",
    "    image_all = [] # define empy array to store image names\n",
    "    \n",
    "    transform = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    # extract features \n",
    "    for index, img_name in enumerate(list_imgs_names):\n",
    "        img_path = os.path.join(path, img_name)\n",
    "        \n",
    "        # Image Read & Resize\n",
    "        image_np = Image.open(img_path) # Read the images\n",
    "        image_np = np.array(image_np)\n",
    "        image_np = resize(image_np, (224, 224), mode='constant') # Resize the images\n",
    "        image_np = torch.from_numpy(image_np).permute(2, 0, 1).float()\n",
    "        image_np = transform(image_np)\n",
    "        image_np = Variable(image_np.unsqueeze(0))   #bs, c, h, w\n",
    "        image_np = image_np.cuda()\n",
    "        \n",
    "        # Extract Feature\n",
    "        feature = feature_extractor(image_np)\n",
    "        feature = feature.squeeze().cpu().data.numpy()\n",
    "        feature = feature.reshape((1, feature_size)) # Feature Flatten\n",
    "        feature = feature / LA.norm(feature) # Feature Normalization\n",
    "        feature_all[index] = feature\n",
    "        image_all.append(img_name)\n",
    "\n",
    "    time_elapsed = time.time() - start_time\n",
    "\n",
    "    print('Feature extraction complete in {:.02f}s'.format(time_elapsed % 60))\n",
    "\n",
    "    return feature_all, image_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_deep_feature(feature_extractor, feature_size):\n",
    "    # Extract features from the dataset\n",
    "    print('Extract features from data')\n",
    "    path = './data'\n",
    "    feats, image_list = extract_deep_features(path, feature_extractor, feature_size=feature_size)\n",
    "\n",
    "    # test image path\n",
    "    print('Extract features from query image')\n",
    "    test = './test'\n",
    "    feat_single, image = extract_deep_features(test, feature_extractor, feature_size=feature_size)\n",
    "    \n",
    "    # Calculate the scores\n",
    "    scores  = np.dot(feat_single, feats.T)\n",
    "    sort_ind = np.argsort(scores)[0][::-1] # sort the scores\n",
    "    scores = scores[0, sort_ind]\n",
    "\n",
    "    # Show the results\n",
    "    maxres = 10\n",
    "    imlist = [image_list[index] for i, index in enumerate(sort_ind[0:maxres])]\n",
    "    print (\"top %d images in order are: \" %maxres, imlist)\n",
    "\n",
    "    fig=plt.figure(figsize=(16, 10))\n",
    "    for i in range(len(imlist)):\n",
    "        sample = imlist[i]\n",
    "        img = mpimg.imread('./data' + '/' + sample)\n",
    "        ax = fig.add_subplot(2, 5, i+1)\n",
    "        ax.autoscale()\n",
    "        plt.tight_layout()\n",
    "        plt.imshow(img, interpolation='nearest')\n",
    "        ax.set_title('{:.3f}%'.format(scores[i]))\n",
    "        ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# DenseNet Image Retrieval Results\n",
    "test_deep_feature(???, feature_size=???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
